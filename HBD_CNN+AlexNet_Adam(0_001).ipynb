{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RomanaNourin/Crime-Activity-Detection/blob/main/HBD_CNN%2BAlexNet_Adam(0_001).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MVs0TdwLj1A",
        "outputId": "c415690f-90c4-4cfd-b030-32f77bdac65b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.15\n",
            "  Downloading tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (18.1.1)\n",
            "Collecting ml-dtypes~=0.2.0 (from tensorflow==2.15)\n",
            "  Downloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (4.12.2)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.15)\n",
            "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15) (1.64.1)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow==2.15)\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow==2.15)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow==2.15)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.15) (0.44.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (3.0.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15) (3.2.2)\n",
            "Downloading tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, ml-dtypes, keras, tensorboard, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.16.0\n",
            "    Uninstalling wrapt-1.16.0:\n",
            "      Successfully uninstalled wrapt-1.16.0\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.4.1\n",
            "    Uninstalling keras-3.4.1:\n",
            "      Successfully uninstalled keras-3.4.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.0\n",
            "    Uninstalling tensorboard-2.17.0:\n",
            "      Successfully uninstalled tensorboard-2.17.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.0\n",
            "    Uninstalling tensorflow-2.17.0:\n",
            "      Successfully uninstalled tensorflow-2.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorstore 0.1.66 requires ml-dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.15.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.15.0 ml-dtypes-0.2.0 tensorboard-2.15.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 wrapt-1.14.1\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.15\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iz_EYiPExz_b",
        "outputId": "42bf262e-a759-46e9-e5b6-1e62844104e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YEQn4JV6m2G",
        "outputId": "f8bfa44f-75c1-4c9d-b6bb-7660ea82ef1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pafy\n",
            "  Downloading pafy-0.5.5-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Downloading pafy-0.5.5-py2.py3-none-any.whl (35 kB)\n",
            "Installing collected packages: pafy\n",
            "Successfully installed pafy-0.5.5\n"
          ]
        }
      ],
      "source": [
        "!pip install pafy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIchSQzY6vgk",
        "outputId": "fb5f7d8b-51a5-4767-f04e-40a545fb7861"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube-dl\n",
            "  Downloading youtube_dl-2021.12.17-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Downloading youtube_dl-2021.12.17-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/1.9 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: youtube-dl\n",
            "Successfully installed youtube-dl-2021.12.17\n"
          ]
        }
      ],
      "source": [
        "!pip install youtube-dl # install the missing module\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TBWe6kpDGL4B"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "# Base directory containing the dataset (Train and Test folders)\n",
        "base_dir = '/content/drive/MyDrive/Human Behavior dataset (HBD21)/Enhanced_test&train_data'\n",
        "\n",
        "# Directory where frames will be saved\n",
        "output_dir = '/content/drive/MyDrive/Human Behavior dataset (HBD21)'\n",
        "\n",
        "# Number of frames to extract from each video (you can set this to None if you want all frames)\n",
        "frames_per_video = 30\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Function to extract frames from a video and save them as images\n",
        "def extract_frames(video_path, output_folder, frames_to_extract=None):\n",
        "    # Create a VideoCapture object\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # Get total number of frames\n",
        "    frame_rate = int(cap.get(cv2.CAP_PROP_FPS))  # Get the frame rate of the video\n",
        "\n",
        "    # Calculate interval for extracting frames (if specified)\n",
        "    if frames_to_extract:\n",
        "        interval = max(1, frame_count // frames_to_extract)\n",
        "    else:\n",
        "        interval = 1  # Extract all frames\n",
        "\n",
        "    # Loop to read frames\n",
        "    count = 0\n",
        "    extracted_count = 0\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break  # End of video\n",
        "\n",
        "        # Save frame at the specified interval\n",
        "        if count % interval == 0:\n",
        "            frame_filename = os.path.join(output_folder, f\"frame_{count:05d}.jpg\")\n",
        "            cv2.imwrite(frame_filename, frame)\n",
        "            extracted_count += 1\n",
        "\n",
        "        count += 1\n",
        "        # Stop if we've extracted the specified number of frames\n",
        "        if frames_to_extract and extracted_count >= frames_to_extract:\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "# Loop through Train and Test folders\n",
        "for dataset_type in ['Train', 'Test']:\n",
        "    dataset_dir = os.path.join(base_dir, dataset_type)\n",
        "\n",
        "    # Loop through each class/category folder in the dataset (e.g., Abuse, Arrest, etc.)\n",
        "    for class_name in os.listdir(dataset_dir):\n",
        "        class_dir = os.path.join(dataset_dir, class_name)\n",
        "\n",
        "        # Check if the current item is a directory\n",
        "        if not os.path.isdir(class_dir):\n",
        "            continue\n",
        "\n",
        "        # Loop through all video files in the current class folder\n",
        "        for video_file in os.listdir(class_dir):\n",
        "            video_path = os.path.join(class_dir, video_file)\n",
        "\n",
        "            # Skip non-video files (if any)\n",
        "            if not video_file.endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
        "                continue\n",
        "\n",
        "            # Create a folder for each video under the correct class in the output directory\n",
        "            output_class_dir = os.path.join(output_dir, dataset_type, class_name)\n",
        "            if not os.path.exists(output_class_dir):\n",
        "                os.makedirs(output_class_dir)\n",
        "\n",
        "            # Create a folder specific to this video within the class folder\n",
        "            video_name = os.path.splitext(video_file)[0]\n",
        "            output_video_dir = os.path.join(output_class_dir, video_name)\n",
        "            if not os.path.exists(output_video_dir):\n",
        "                os.makedirs(output_video_dir)\n",
        "\n",
        "            # Extract frames from the video and save them\n",
        "            extract_frames(video_path, output_video_dir, frames_per_video)\n",
        "\n",
        "print(\"Frames extraction with labels complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NA2OKCT2HHQU"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import cv2\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2g_ffrv8HN6b"
      },
      "outputs": [],
      "source": [
        "test_dir = '/content/drive/MyDrive/Human Behavior dataset (HBD21)/Train'\n",
        "train_dir = '/content/drive/MyDrive/Human Behavior dataset (HBD21)/Test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XThTOG0RHYi_"
      },
      "outputs": [],
      "source": [
        "# Define the categories and labels\n",
        "categories_labels = {'assault_violence': 0, 'gun_violence': 1, 'normal_actions': 2, 'sabotage_violence': 3}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZjXTwB2wHw5g"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "def load_data(base_dir, categories_labels):\n",
        "    data = []\n",
        "\n",
        "    # Go through each category\n",
        "    for category, label in categories_labels.items():\n",
        "        # The path to the category directory\n",
        "        category_dir = os.path.join(base_dir, category)\n",
        "        print(f\"Checking category directory: {category_dir}\")  # Debugging print\n",
        "\n",
        "        # Make sure the directory exists\n",
        "        if os.path.isdir(category_dir):\n",
        "            # Go through each subfolder (video name) in the category directory\n",
        "            for video_subfolder in os.listdir(category_dir):\n",
        "                video_subfolder_path = os.path.join(category_dir, video_subfolder)\n",
        "                print(f\"  Checking video subfolder: {video_subfolder_path}\")  # Debugging print\n",
        "\n",
        "                # Ensure it's a directory (subfolder)\n",
        "                if os.path.isdir(video_subfolder_path):\n",
        "                    # Go through each image in the video subfolder\n",
        "                    for filename in os.listdir(video_subfolder_path):\n",
        "                        # Make sure the file is an image\n",
        "                        if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n",
        "                            # The path to the image\n",
        "                            image_path = os.path.join(video_subfolder_path, filename)\n",
        "                            print(f\"    Found image: {image_path}\")  # Debugging print\n",
        "\n",
        "                            try:\n",
        "                                # Load the image\n",
        "                                image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "                                # Check if the image was loaded successfully\n",
        "                                if image is None:\n",
        "                                    print(f\"Error: Could not read image {image_path}\")\n",
        "                                    continue\n",
        "\n",
        "                                # Resize the image\n",
        "                                image = cv2.resize(image, (128, 128))\n",
        "\n",
        "                                # Reshape the image to a 4D array (ImageDataGenerator requires 4D array)\n",
        "                                image = image.reshape((1,) + image.shape + (1,))\n",
        "\n",
        "                                # Add the image and its label to the data\n",
        "                                data.append([image, label])\n",
        "                            except Exception as e:\n",
        "                                print(f\"Error processing image {image_path}: {e}\")\n",
        "\n",
        "        else:\n",
        "            print(f\"Category directory {category_dir} does not exist!\")  # Debugging print\n",
        "\n",
        "    return data\n",
        "\n",
        "# Directories where the data is stored\n",
        "train_dir = '/content/drive/MyDrive/Human Behavior dataset (HBD21)/Train'\n",
        "test_dir = '/content/drive/MyDrive/Human Behavior dataset (HBD21)/Test'\n",
        "\n",
        "# Category labels (You can replace this with your actual category labels)\n",
        "categories_labels = {'assault_violence': 0, 'gun_violence': 1, 'normal_actions': 2, 'sabotage_violence': 3}\n",
        "# Load the training and test data\n",
        "training_data = load_data(train_dir, categories_labels)\n",
        "test_data = load_data(test_dir, categories_labels)\n",
        "\n",
        "# Combine the training and test data\n",
        "total_data = training_data + test_data\n",
        "\n",
        "print(f\"Loaded {len(total_data)} images.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wJgxEhgnHzWi"
      },
      "outputs": [],
      "source": [
        "len(total_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GrP5LNMbLDau"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def show_sample_images(data, categories_labels, num_samples=5):\n",
        "    # Reverse the categories_labels dictionary to map labels back to category names\n",
        "    labels_to_categories = {v: k for k, v in categories_labels.items()}\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "\n",
        "    # Randomly select a few images to display\n",
        "    indices = np.random.choice(len(data), num_samples, replace=False)\n",
        "\n",
        "    for i, idx in enumerate(indices):\n",
        "        image, label = data[idx]\n",
        "\n",
        "        # Reshape the image to display correctly (50x50 in your case)\n",
        "        image = image.reshape(128, 128)\n",
        "\n",
        "        # Get the corresponding category name for the label\n",
        "        category_name = labels_to_categories[label]\n",
        "\n",
        "        # Display the image\n",
        "        plt.subplot(1, num_samples, i + 1)\n",
        "        plt.imshow(image, cmap='gray')\n",
        "        plt.title(category_name)\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Assuming you have a dictionary 'categories_labels'\n",
        "# e.g., categories_labels = {'Abuse': 0, 'Arrest': 1, 'Arson': 2, ...}\n",
        "\n",
        "# Display 5 sample images from total_data with their categorical labels\n",
        "show_sample_images(total_data, categories_labels, num_samples=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Xw0jFZhYLQy_"
      },
      "outputs": [],
      "source": [
        "!sudo pip install keras\n",
        "!pip install np_utils\n",
        "!pip install pydot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bWnJnkklLXOt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.python.keras.utils import np_utils\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU\n",
        "from keras.layers import concatenate\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.optimizers import RMSprop, SGD, Adam\n",
        "from tensorflow.python.keras.callbacks import ModelCheckpoint, CSVLogger, Callback\n",
        "import time\n",
        "\n",
        "\n",
        "# Initialize lists to store the images and the labels\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Go through each image and its label in the total_data\n",
        "for image, label in total_data:\n",
        "    images.append(image)\n",
        "    labels.append(label)\n",
        "\n",
        "# Convert the lists into numpy arrays\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "print(images.shape)\n",
        "\n",
        "# Reshape images if necessary for AlexNet\n",
        "images_alex = images.reshape(images.shape[0], 128, 128, 1)  # Assuming grayscale images of size 128x128\n",
        "\n",
        "# Set a seed for reproducibility\n",
        "seed = 42\n",
        "\n",
        "# Split the data into training and testing sets for CNN and AlexNet\n",
        "train_images_cnn, test_images_cnn, train_labels_cnn, test_labels_cnn = train_test_split(images, labels, test_size=0.3, random_state=seed)\n",
        "train_images_alex, test_images_alex, train_labels_alex, test_labels_alex = train_test_split(images_alex, labels, test_size=0.3, random_state=seed)\n",
        "\n",
        "# Convert labels to categorical for CNN and AlexNet\n",
        "train_labels = np_utils.to_categorical(train_labels_cnn, len(categories_labels))\n",
        "test_labels = np_utils.to_categorical(test_labels_cnn, len(categories_labels))\n",
        "train_labels_alex = np_utils.to_categorical(train_labels_alex, len(categories_labels))\n",
        "test_labels_alex = np_utils.to_categorical(test_labels_alex, len(categories_labels))\n",
        "\n",
        "# CNN Model\n",
        "model_CNN = Sequential()\n",
        "model_CNN.add(Conv2D(64, kernel_size=(3, 3), padding='same', input_shape=(128, 128, 1)))\n",
        "model_CNN.add(LeakyReLU(alpha=0.1))\n",
        "model_CNN.add(MaxPooling2D((2, 2), padding='same'))\n",
        "model_CNN.add(Dropout(0.25))\n",
        "model_CNN.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model_CNN.add(LeakyReLU(alpha=0.1))\n",
        "model_CNN.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "model_CNN.add(Dropout(0.25))\n",
        "model_CNN.add(Conv2D(256, (3, 3), padding='same'))\n",
        "model_CNN.add(LeakyReLU(alpha=0.1))\n",
        "model_CNN.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "model_CNN.add(Dropout(0.4))\n",
        "model_CNN.add(Flatten())\n",
        "model_CNN.add(Dense(256))\n",
        "model_CNN.add(LeakyReLU(alpha=0.1))\n",
        "model_CNN.add(Dropout(0.5))\n",
        "\n",
        "# AlexNet Model\n",
        "model_alexnet = Sequential()\n",
        "model_alexnet.add(Conv2D(filters=96, input_shape=(128, 128, 1), kernel_size=(11, 11), strides=(4, 4), padding='same'))\n",
        "model_alexnet.add(LeakyReLU(alpha=0.1))\n",
        "model_alexnet.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "model_alexnet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1), padding='same'))\n",
        "model_alexnet.add(LeakyReLU(alpha=0.1))\n",
        "model_alexnet.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "model_alexnet.add(Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding='same'))\n",
        "model_alexnet.add(LeakyReLU(alpha=0.1))\n",
        "model_alexnet.add(Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding='same'))\n",
        "model_alexnet.add(LeakyReLU(alpha=0.1))\n",
        "model_alexnet.add(Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='same'))\n",
        "model_alexnet.add(LeakyReLU(alpha=0.1))\n",
        "model_alexnet.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "model_alexnet.add(Flatten())\n",
        "model_alexnet.add(Dense(4096))\n",
        "model_alexnet.add(LeakyReLU(alpha=0.1))\n",
        "model_alexnet.add(Dropout(0.5))\n",
        "model_alexnet.add(Dense(4096))\n",
        "model_alexnet.add(LeakyReLU(alpha=0.1))\n",
        "model_alexnet.add(Dropout(0.5))\n",
        "model_alexnet.add(Dense(1000))\n",
        "model_alexnet.add(LeakyReLU(alpha=0.1))\n",
        "model_alexnet.add(Dropout(0.5))\n",
        "\n",
        "# Combine CNN and AlexNet model\n",
        "nb_classes = 4\n",
        "combined = concatenate([model_CNN.output, model_alexnet.output], axis=-1)\n",
        "output = Dense(nb_classes, activation='softmax')(combined)\n",
        "model_final = Model(inputs=[model_CNN.input, model_alexnet.input], outputs=output)\n",
        "\n",
        "# Plot and compile the model\n",
        "plot_model(model_final, to_file='model_plot_alexnet.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "# Define Hybrid Optimizer Callback\n",
        "class HybridOptimizer(Callback):\n",
        "    def __init__(self, sgd, adam, switch_epoch):\n",
        "        super(HybridOptimizer, self).__init__()\n",
        "        self.sgd = sgd\n",
        "        self.adam = adam\n",
        "        self.switch_epoch = switch_epoch\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        if epoch < self.switch_epoch:\n",
        "            print(f\"Epoch {epoch + 1}: Using Adam optimizer\")\n",
        "            self.model.optimizer = self.adam\n",
        "        else:\n",
        "            print(f\"Epoch {epoch + 1}: Switching to SGD optimizer\")\n",
        "            self.model.optimizer = self.sgd\n",
        "\n",
        "# Initialize optimizers\n",
        "adam = Adam(learning_rate=0.001)\n",
        "sgd = SGD(learning_rate=0.01, momentum=0.9)\n",
        "\n",
        "# Use Adam for the first 10 epochs, then switch to SGD\n",
        "switch_epoch = 10\n",
        "\n",
        "# Initialize hybrid optimizer callback\n",
        "hybrid_optimizer_callback = HybridOptimizer(sgd, adam, switch_epoch)\n",
        "\n",
        "# Callbacks\n",
        "csv_logger = CSVLogger('training_alexnet.log', separator=',', append=False)\n",
        "mc = ModelCheckpoint('Model.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
        "\n",
        "# Compile model with Adam optimizer initially\n",
        "model_final.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "\n",
        "# Training\n",
        "time1 = time.time()\n",
        "history = model_final.fit([train_images_cnn, train_images_alex], train_labels_alex,\n",
        "                          batch_size=64, epochs=20,\n",
        "                          validation_data=([test_images_cnn, test_images_alex], test_labels_alex),\n",
        "                          callbacks=[mc, csv_logger, hybrid_optimizer_callback])\n",
        "print((\"Training time=\", time.time() - time1))\n",
        "\n",
        "# Save training history\n",
        "np.save(\"Model_history.npy\", history.history)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "J6ea6A9ERL8T"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "fashion_model = load_model('/content/Model.h5') # load model\n",
        "fashion_model.summary() # summarize model.\n",
        "\n",
        "from contextlib import redirect_stdout\n",
        "with open('/content/Model.h5'+\".xls\", 'w') as f:\n",
        "    with redirect_stdout(f):\n",
        "        fashion_model.summary()\n",
        "\n",
        "val_loss, val_accuracy=fashion_model.evaluate([test_images_cnn, test_images_alex] ,test_labels) ## to get test accuracy and losses\n",
        "print(val_loss, val_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9Mt3-UgyYQkl"
      },
      "outputs": [],
      "source": [
        "time2=time.time()\n",
        "predict_prob=fashion_model.predict([test_images_cnn, test_images_alex])\n",
        "y_pred=np.argmax(predict_prob,axis=1)\n",
        "print ('classification time:', time.time()-time2)\n",
        "\n",
        "##print (y_pred)\n",
        "y_true=np.argmax(test_labels, axis=1) # Use test_labels instead of test_labels_cnn\n",
        "from sklearn.metrics import precision_recall_fscore_support as score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print (cm)\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "print('Precision: %f' % precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "print('Recall: %f' % recall)\n",
        "# f1: tp / (tp + fp + fn)\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "print('F1 score: %f' % f1)\n",
        "#-----------  IoU\n",
        "from sklearn.metrics import jaccard_score\n",
        "print ('IoU:', jaccard_score(y_true, y_pred, average='micro'))\n",
        "\n",
        "\n",
        "test_eval = fashion_model.evaluate([test_images_cnn, test_images_alex], test_labels) # Use test_labels instead of test_labels_cnn\n",
        "\n",
        "loss, accuracy = fashion_model.evaluate([train_images_cnn, train_images_alex], train_labels) # Use train_labels instead of train_labels_cnn\n",
        "print('loss_train: ', loss, 'accuracy_train: ', accuracy)\n",
        "print('Test loss:', test_eval[0], 'Test accuracy:', test_eval[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZEtvtaWiYTQZ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def show_validation_images(test_images_cnn, test_images_lstm, y_true, y_pred, categories_labels, num_samples=5):\n",
        "    # Reverse the categories_labels dictionary to map labels back to category names\n",
        "    labels_to_categories = {v: k for k, v in categories_labels.items()}\n",
        "\n",
        "    plt.figure(figsize=(15, 15))\n",
        "\n",
        "    # Randomly select a few images to display\n",
        "    indices = np.random.choice(len(test_images_cnn), num_samples, replace=False)\n",
        "\n",
        "    for i, idx in enumerate(indices):\n",
        "        image = test_images_cnn[idx]\n",
        "\n",
        "        # Get the true and predicted labels\n",
        "        true_label = labels_to_categories[y_true[idx]]\n",
        "        predicted_label = labels_to_categories[y_pred[idx]]\n",
        "\n",
        "        # Reshape the image to display correctly (50x50 in your case)\n",
        "        image = image.reshape(128, 128)\n",
        "\n",
        "        # Display the image\n",
        "        plt.subplot(1, num_samples, i + 1)\n",
        "        plt.imshow(image, cmap='gray')\n",
        "        plt.title(f\"True: {true_label}\\nPredicted: {predicted_label}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Assuming y_true and y_pred are already calculated\n",
        "# y_true is already in the correct format, no need to apply argmax\n",
        "# y_true = np.argmax(test_labels_cnn, axis=1)  # Convert one-hot encoded labels to class integers\n",
        "\n",
        "# Display 5 validation images with their true and predicted labels\n",
        "show_validation_images(test_images_cnn, test_images_alex, y_true, y_pred, categories_labels, num_samples=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GBMZbg5AYYRB"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict=history.history\n",
        "loss_values=history_dict['loss']\n",
        "val_loss_values=history_dict['val_loss']\n",
        "acc_values=history_dict['accuracy']\n",
        "val_acc_values=history_dict['val_accuracy']\n",
        "epochs=range(1, len(acc_values)+1)\n",
        "def smooth_curve(points, factor=0.8):\n",
        "    smoothed_points = []\n",
        "    for point in points:\n",
        "        if smoothed_points:\n",
        "            previous = smoothed_points[-1]\n",
        "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
        "        else:\n",
        "            smoothed_points.append(point)\n",
        "    return smoothed_points\n",
        "loss_values=smooth_curve(loss_values)\n",
        "val_loss_values=smooth_curve(val_loss_values)\n",
        "acc_values=smooth_curve(acc_values)\n",
        "val_acc_values=smooth_curve(val_acc_values)\n",
        "\n",
        "font = {'family' : 'serif',\n",
        "        'color'  : 'black',\n",
        "        'weight' : 'normal',\n",
        "        'size'   : 12}\n",
        "\n",
        "\n",
        "plt.plot(epochs, acc_values, 'r-', label='Training acc')\n",
        "plt.plot(epochs, val_acc_values, 'g', label='Validation acc')\n",
        "plt.title('Training and Validation acc', fontdict=font)\n",
        "plt.xlabel('Epochs', fontdict=font)\n",
        "plt.ylabel('Accuracy', fontdict=font)\n",
        "plt.legend()\n",
        "plt.savefig(\"accuracy\"+'CNN_AlexNet'+\".png\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epochs, loss_values, 'b-', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'r', label='Validation loss')\n",
        "plt.title('Training and Validation loss', fontdict=font)\n",
        "plt.xlabel('Epochs',fontdict=font)\n",
        "plt.ylabel('Loss',fontdict=font)\n",
        "plt.legend()\n",
        "plt.savefig(\"loss\"+'CNN_AlexNet'+\".png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Xfg0cFHBYdMl"
      },
      "outputs": [],
      "source": [
        "class_names = ['assault_violence', 'gun_violence', 'normal_actions', 'sabotage_violence']\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    #    classes = classes[unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 10))\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "font = {'family' : 'serif',\n",
        "        'color'  : 'black',\n",
        "        'weight' : 'normal',\n",
        "        'size'   : 14}\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plot_confusion_matrix(y_true, y_pred, classes=class_names,\n",
        "                      title='Confusion matrix, without normalization')\n",
        "plt.savefig('confusion matrix1'+'CNN_AlexNet'+'.png')\n",
        "plt.show()\n",
        "# Plot normalized confusion matrix\n",
        "plot_confusion_matrix(y_true, y_pred, classes=class_names, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "plt.savefig('confusion matrix2'+'CNN_AlexNet'+'.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6BYT1DmjYvmT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Step 1: Make predictions using the trained model on test data\n",
        "predictions = model_final.predict([test_images_cnn, test_images_alex])\n",
        "\n",
        "# Step 2: Convert predictions from one-hot encoding back to class labels\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Convert true labels (from one-hot encoding) back to class labels\n",
        "true_classes = np.argmax(test_labels, axis=1)\n",
        "\n",
        "# Step 3: Generate the confusion matrix\n",
        "cm = confusion_matrix(true_classes, predicted_classes)\n",
        "\n",
        "# Step 4: Visualize the confusion matrix\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=categories_labels)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "\n",
        "# Step 5: Show the plot\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cvkwbMuUY1hY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix, precision_score, recall_score, f1_score, jaccard_score, roc_auc_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# Timing the predictions\n",
        "time2 = time.time()\n",
        "predict_prob = fashion_model.predict([test_images_cnn, test_images_alex])\n",
        "y_pred = np.argmax(predict_prob, axis=1)\n",
        "print('Classification time:', time.time() - time2)\n",
        "\n",
        "# True labels\n",
        "y_true = np.argmax(test_labels, axis=1)\n",
        "\n",
        "# Classification metrics\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(cm)\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "# Precision, recall, F1\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "print('Precision: %f' % precision)\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "print('Recall: %f' % recall)\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "print('F1 score: %f' % f1)\n",
        "\n",
        "# Intersection over Union (IoU)\n",
        "print('IoU:', jaccard_score(y_true, y_pred, average='micro'))\n",
        "\n",
        "# Model evaluation\n",
        "test_eval = fashion_model.evaluate([test_images_cnn, test_images_alex], test_labels)\n",
        "loss, accuracy = fashion_model.evaluate([train_images_cnn, train_images_alex], train_labels)\n",
        "print('Train loss:', loss, 'Train accuracy:', accuracy)\n",
        "print('Test loss:', test_eval[0], 'Test accuracy:', test_eval[1])\n",
        "\n",
        "# --------- ROC-AUC Curve ---------\n",
        "\n",
        "# Step 1: Binarize the true labels for the one-vs-rest approach\n",
        "n_classes = len(np.unique(y_true))  # Total number of classes\n",
        "y_true_bin = label_binarize(y_true, classes=range(n_classes))\n",
        "\n",
        "# Step 2: Calculate ROC curve and AUC for each class\n",
        "fpr = dict()  # False Positive Rate for each class\n",
        "tpr = dict()  # True Positive Rate for each class\n",
        "roc_auc = dict()  # AUC for each class\n",
        "\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], predict_prob[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Step 3: Plot the ROC curve for each class with AUC\n",
        "plt.figure(figsize=(10, 8))\n",
        "for i in range(n_classes):\n",
        "    plt.plot(fpr[i], tpr[i], label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
        "\n",
        "# Plot diagonal line representing random guessing\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guessing')\n",
        "\n",
        "# Customize the plot\n",
        "plt.title('ROC-AUC Curve for Suspecious Activity Detection')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "\n",
        "# Step 4: Show the plot\n",
        "plt.show()\n",
        "\n",
        "# Step 5: Calculate and print overall AUC score (micro and macro average)\n",
        "micro_roc_auc = roc_auc_score(y_true_bin, predict_prob, average='micro')\n",
        "macro_roc_auc = roc_auc_score(y_true_bin, predict_prob, average='macro')\n",
        "\n",
        "print(f'Micro-average AUC: {micro_roc_auc:.2f}')\n",
        "print(f'Macro-average AUC: {macro_roc_auc:.2f}')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyPrMKYevturkMn7oV202Irp",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}